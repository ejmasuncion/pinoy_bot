{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b13e99",
   "metadata": {},
   "source": [
    "Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ddb652",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91402916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7bc1a6",
   "metadata": {},
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1964f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_words(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_cleaned = df.dropna(subset=['word'])\n",
    "    df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "    return df_cleaned\n",
    "\n",
    "df = drop_null_words(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a56c2f",
   "metadata": {},
   "source": [
    "Feature Engineering / Preprocessing:\n",
    "\n",
    "Target Features:\n",
    " - Word length\n",
    " - Vowel / Word Ratio\n",
    " - Consonant / Word Ratio\n",
    " - Look at common letters not present in filipino word (c, x, z, f, etc.)\n",
    " - Common NGram counts for Filipino and English words\n",
    "    - ng\n",
    "    - ch, sh, etc.\n",
    "    - Filipino prefixes (um, in, etc.)\n",
    "-  Check if the word is a (noun, verb, etc based on the sentence)\n",
    "\n",
    "\n",
    "Note: normalize data if needed (check sklearn.preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"is_spelling_correct\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c7f53",
   "metadata": {},
   "source": [
    "Length Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_length'] = df['word'].apply(lambda w: len(str(w)) if isinstance(w, str) else 0)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a5306",
   "metadata": {},
   "source": [
    "Vowel and consonant ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8093bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowel_consonant_ratio(word):\n",
    "    if not isinstance(word, str):  ### if the word does not have alphabet\n",
    "        return 0.0\n",
    "    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U']\n",
    "    num_vowels = sum(1 for ch in word if ch.isalpha() and ch in vowels)\n",
    "    num_consonants = sum(1 for ch in word)\n",
    "\n",
    "    if num_consonants == 0:\n",
    "        return 1.0 if num_vowels > 0 else 0.0\n",
    "    return num_vowels / num_consonants\n",
    "\n",
    "def vowel_word_ratio(word):\n",
    "    if not isinstance(word, str):\n",
    "        return 0.0\n",
    "    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U']\n",
    "    num_vowels = sum(1 for ch in word if ch.isalpha() and ch in vowels)\n",
    "    num_consonants = sum(1 for ch in word)\n",
    "\n",
    "    if num_consonants == 0:\n",
    "        return 1.0 if num_vowels > 0 else 0.0\n",
    "    return num_vowels / num_consonants\n",
    "\n",
    "df['vowel_word_ratio'] = df['word'].apply(vowel_word_ratio)\n",
    "df['vowel_consonant_ratio'] = df['word'].apply(vowel_consonant_ratio)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ffaa3f",
   "metadata": {},
   "source": [
    "Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe17e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filipino_bigrams = ['ng', 'ka', 'in', 'ay', 'um', 'mag', 'nag', 'may', 'na', 'sa']\n",
    "\n",
    "def count_filipino_bigrams(word: str, target_bigrams: list) -> int:\n",
    "    word_lower = str(word).lower()\n",
    "    total_count = 0\n",
    "    \n",
    "    for bigram in target_bigrams:\n",
    "        # Count all non-overlapping occurrences of the bigram in the word\n",
    "        total_count += word_lower.count(bigram)\n",
    "            \n",
    "    return total_count\n",
    "\n",
    "df['filipino_bigram_count'] = df['word'].apply(\n",
    "    lambda x: count_filipino_bigrams(x, filipino_bigrams)\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2886a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_bigrams = [\n",
    "    'th', 'sh', 'ch', 'wh', 'ed', 'ly', 'er', \n",
    "    'es', 'ou', 'ea', 'io', 'al', 'is', 'at', \n",
    "    'an', 'he'\n",
    "]\n",
    "\n",
    "def count_english_bigrams(word: str, target_bigrams: list) -> int:\n",
    "    word_lower = str(word).lower()\n",
    "    total_count = 0\n",
    "    \n",
    "    for bigram in target_bigrams:\n",
    "        # Count all non-overlapping occurrences of the bigram in the word\n",
    "        total_count += word_lower.count(bigram)\n",
    "            \n",
    "    return total_count\n",
    "\n",
    "df['english_bigram_count'] = df['word'].apply(\n",
    "    lambda x: count_filipino_bigrams(x, english_bigrams)\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dc1b52",
   "metadata": {},
   "source": [
    "Foreign Alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c641523",
   "metadata": {},
   "outputs": [],
   "source": [
    "foreign_letters = ['c', 'f', 'j', 'q', 'v', 'x', 'z']\n",
    "\n",
    "def check_foreign_alphabet(word: str) -> int:\n",
    "    word_lower = str(word).lower()\n",
    "\n",
    "    for letter in word_lower:\n",
    "        if letter in foreign_letters:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df['has_foreign_alphabet'] = df['word'].apply(check_foreign_alphabet)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4771ad04",
   "metadata": {},
   "source": [
    "Train Test Split\n",
    "\n",
    "- Check the sklearn to split.\n",
    "- Model should be 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65371a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['word_length', 'vowel_word_ratio', 'vowel_consonant_ratio',\n",
    "                'filipino_bigram_count', 'english_bigram_count', 'has_foreign_alphabet']\n",
    "X = df[feature_cols]\n",
    "y = df['label']\n",
    "print(len(X),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f511c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Split the dataset to 15% test size and 85% train and validation size\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "## Split the train and validation set to 15% validation size and 85% train size\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42)\n",
    "\n",
    "print(\"X_train: \",  len(X_train))\n",
    "print(\"X_val: \", len(X_val))\n",
    "print(\"y_train: \", len(y_train))\n",
    "print(\"y_val: \", len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395cab97",
   "metadata": {},
   "source": [
    "Imbalance Data:\n",
    "\n",
    "Check these techniques in imblearn library:\n",
    " - SMOTE\n",
    " - ADYSN\n",
    " - Undersampling\n",
    " - Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c105a",
   "metadata": {},
   "source": [
    "SMOTE Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote_sampler = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote_sampler.fit_resample(\n",
    "    X_train, \n",
    "    y_train\n",
    ")\n",
    "print(\"Original training set size:\", len(y_train))\n",
    "print(\"Resampled training set size:\", len(y_train_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1090d4",
   "metadata": {},
   "source": [
    "Naive Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd234704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "X_resample, y_resample = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Original training set size\", len(y_train))\n",
    "print(len((y_resample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e47359",
   "metadata": {},
   "source": [
    "Naive Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "\n",
    "X_resample, y_resample = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Original training set size\", len(y_train))\n",
    "print(len((y_resample)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2292a6a",
   "metadata": {},
   "source": [
    "ML Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0212f3ed",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0683c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_val_pred = nb_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"\\nValidation Set Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "## Hypertune by changing model parameters if needed (var_smoothing for GaussianNB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278799a8",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7efc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"\\nValidation Set Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d69d883",
   "metadata": {},
   "source": [
    "Model Validation:\n",
    "- Confusion Matrix\n",
    "- Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbf839",
   "metadata": {},
   "source": [
    "Naive Bayes Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "y_test_pred = nb_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: **{test_accuracy:.4f}**\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Naive Bayes Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f7977",
   "metadata": {},
   "source": [
    "Decision Trees Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef251a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: **{test_accuracy:.4f}**\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Decision Trees Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinoybotenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
